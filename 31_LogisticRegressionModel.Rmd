```{r load-data}
library(here)

source(here("00_requirements.R")) 

load(here("processed_data", "cleaned_data.RData"))
```

```{r}
glimpse(cleaned_data)
```

Build a basic logistic regression model with hand-picked variables to have a "base" model for comparisons.

```{r}
cleaned_data_clean <- cleaned_data %>%
  clean_names()

cleaned_data_clean <- cleaned_data_clean %>%
  mutate(voting_results_2024 = as.factor(voting_results_2024))

cleaned_data_clean$voting_results_2024 <- relevel(cleaned_data_clean$voting_results_2024, ref = "D")

set.seed(123) 


data_split <- initial_split(cleaned_data_clean, prop = 0.75, strata = voting_results_2024)

train_data <- training(data_split)
test_data  <- testing(data_split)


model_logistic <- glm(
  voting_results_2024 ~ median_household_income + 
                        unemployment_rate_august_2025 + 
                        white + 
                        black + 
                        hispanic,
  data = train_data,
  family = "binomial"
)

# See the summary of the model (coefficients, p-values, etc.)
summary(model_logistic)

probabilities <- predict(model_logistic, newdata = test_data, type = "response")

predictions <- ifelse(probabilities > 0.5, "R", "D")

confusion_matrix <- table(
  Predicted = predictions, 
  Actual = test_data$voting_results_2024
)

print(confusion_matrix)

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

print(paste("Model Accuracy on Test Data:", round(accuracy * 100, 2), "%"))
```




Backwards Selection Model.

```{r}
df = data.frame(cleaned_data)


# Clean column names
df_clean <- df %>%
  clean_names()

df_clean <- df_clean %>%
  mutate(voting_results_2024 = as.factor(voting_results_2024))

# Set the reference level to "D". This means the model will be
# predicting the probability of "R" (the other level).
# For glmnet, we will use 0 for "D" and 1 for "R" later.
df_clean$voting_results_2024 <- relevel(df_clean$voting_results_2024, ref = "D")

set.seed(123)

# 75/25 split
data_split <- initial_split(df_clean, prop = 0.75, strata = voting_results_2024)

train_data <- training(data_split)
test_data  <- testing(data_split)

print(paste(
  "Data split:",
  "Training set size:", nrow(train_data),
  "Test set size:", nrow(test_data)
))



# full list of predictors
all_predictors_formula <- as.formula(
  ~ black + hispanic + asian + american_indian_or_alaska_native +
    native_hawaiian_or_pacific_islander + multiple_races +
    bicycle + walked + taxi_motorcycle_or_other + public_transportation +
    worked_at_home + carpool + percentage_of_households_that_own_guns +
    gun_ownership_num_of_gun_licenses_num_2022 + covid_deaths +
    covid_pct_of_total + crude_covid_rate + aa_covid_rate +
    crude_covid_rate_ann + aa_covid_rate_ann +
    unemployment_rate_august_2025 + median_household_income +
    electoral_college_votes
)



predictor_vars <- all.vars(all_predictors_formula)
outcome_var <- "voting_results_2024"
all_vars_to_check <- c(outcome_var, predictor_vars)

# Filter train_data for complete cases
train_data_complete <- train_data[
  complete.cases(train_data[, all_vars_to_check]),
]

# Create the 'x' matrix for training from the complete data
train_x <- model.matrix(all_predictors_formula, data = train_data_complete)[, -1] # fix for glmnet

# Create the 'y' vector for training from the complete data
train_y <- train_data_complete$voting_results_2024


# Using cross-validation
set.seed(123)

cv_lasso <- cv.glmnet(train_x,
  train_y,
  family = "binomial",
  alpha = 1
)



print(paste("Optimal lambda (lambda.min):", cv_lasso$lambda.min))

# Get the coefficients
lasso_coeffs <- coef(cv_lasso, s = "lambda.min")
print(lasso_coeffs)


print(' ')
print("<---------------------------------- Evaluating final model ---------------------------------->")
print(' ')

test_data_complete <- test_data[
  complete.cases(test_data[, all_vars_to_check]),
]


# Create 'x' matrix for test data from the complete data
test_x <- model.matrix(all_predictors_formula, data = test_data_complete)[, -1]

test_y_actuals <- test_data_complete$voting_results_2024


predictions <- predict(cv_lasso,
  newx = test_x,
  s = "lambda.min",
  type = "class"
)

if (length(predictions) > 0) {
  confusion_matrix <- table(
    Predicted = predictions,
    Actual = test_y_actuals
  )

  print("Confusion Matrix (Test Data):")
  print(confusion_matrix)

  # Calculate accuracy
  accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
  print(paste("Model Accuracy on Test Data:", round(accuracy * 100, 2), "%"))
} else {
  print("No complete cases found in the test set to make predictions.")
}

```